{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Sequence Modeling with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1490, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('dataset.csv')  # Make sure your CSV file is in the correct path\n",
    "text_col = 'Text'\n",
    "label_col = 'Category'\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# EXERCISE 1: TEXT PREPROCESSING\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess text data\n",
    "    TODO: Complete this function to:\n",
    "    1. Convert text to lowercase\n",
    "    2. Remove all characters except letters and spaces using regex\n",
    "    3. Return the cleaned text\n",
    "    \"\"\"\n",
    "    # TODO: Convert to lowercase\n",
    "    text = # YOUR CODE HERE\n",
    "    \n",
    "    # TODO: Remove non-alphabetic characters (keep only letters and spaces)\n",
    "    text = # YOUR CODE HERE (use re.sub with pattern r'[^a-z\\s]')\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "df[text_col] = df[text_col].astype(str).apply(clean_text)\n",
    "\n",
    "print(\"Sample cleaned texts:\")\n",
    "print(df[text_col].head(3).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# EXERCISE 2: LABEL ENCODING\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Initialize LabelEncoder and encode the labels\n",
    "encoder = # YOUR CODE HERE\n",
    "df[label_col] = # YOUR CODE HERE (use fit_transform)\n",
    "\n",
    "num_classes = len(encoder.classes_)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Classes: {encoder.classes_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 3: TEXT TOKENIZATION AND PADDING\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Initialize tokenizer with out-of-vocabulary token\n",
    "tokenizer = # YOUR CODE HERE (use oov_token='<OOV>')\n",
    "\n",
    "# TODO: Fit tokenizer on texts\n",
    "# YOUR CODE HERE\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# TODO: Convert texts to sequences\n",
    "sequences = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Pad sequences to max_len=100\n",
    "max_len = 100\n",
    "padded = # YOUR CODE HERE (use pad_sequences with padding='post')\n",
    "\n",
    "print(f\"Padded sequences shape: {padded.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 4: TRAIN-VALIDATION-TEST SPLIT\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data into train (70%), validation (15%), and test (15%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# EXERCISE 5: LOAD PRE-TRAINED EMBEDDINGS (OPTIONAL)\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# EXERCISE 6: BUILD MODEL FUNCTION\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN or LSTM model\n",
    "# TODO: Complete this function to build the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# EXERCISE 7: MODEL TRAINING AND EVALUATION\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build model\n",
    "\n",
    "# TODO: Train the model\n",
    "\n",
    "# TODO: Make predictions on test set\n",
    "\n",
    "\n",
    "# TODO: Generate classification report\n",
    "\n",
    "# TODO: Generate confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 8: VISUALIZATION\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Plot training accuracy\n",
    "\n",
    "# TODO: Plot training loss\n",
    "\n",
    "\n",
    "# TODO: Plot confusion matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# =============================================================================\n",
    "# EXERCISE 9: RESULTS ANALYSIS\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add best validation metrics to results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE COMPLETE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NLP Course - Week 3 Exercise Question.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
